{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1cjoLXodSvi3HwLLpvxFWJ748BeAj35ri","authorship_tag":"ABX9TyPrSTw9TRQFf/Ucs1gWP+j+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xDRQ-cuMsrT5"},"outputs":[],"source":["[1:29 pm, 07/05/2025] Kavya Shree: # Ques 1.ipynb - Data Quality Framework (ISO 8000-based)\n","\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","\n","# Load dataset (replace with your file path or dataset)\n","df = pd.read_csv(\"data.csv\")  # Replace with your file path or method\n","\n","# Initialize result dictionary\n","quality_report = {}\n","\n","# 1. Completeness (% of non-null entries)\n","completeness = df.notnull().mean() * 100\n","quality_report['Completeness (%)'] = completeness.round(2)\n","\n","# 2. Uniqueness (% of unique rows)\n","unique_rows = df.duplicated().sum()\n","uniqueness_percent = 100 * (1 - unique_rows / len(df))\n","quality_report['Uniqueness (%)'] = pd.Series([uniqueness_percent.round(2)] * len(df.columns), index=df.columns)\n","\n","# 3. Validity (% of values conforming to data type of first non-null entry)\n","validity = []\n","for col in df.columns:\n","    first_valid = df[col].dropna().iloc[0] if not df[col].dropna().empty else np.nan\n","    expected_type = type(first_valid)\n","    valid_count = df[col].dropna().apply(lambda x: isinstance(x, expected_type)).sum()\n","    validity_percent = 100 * valid_count / df[col].notnull().sum() if df[col].notnull().sum() > 0 else 0\n","    validity.append(round(validity_percent, 2))\n","quality_report['Validity (%)'] = pd.Series(validity, index=df.columns)\n","\n","# 4. Consistency (based on categorical columns having <50% unique values)\n","def check_consistency(col):\n","    if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n","        unique_ratio = df[col].nunique() / df[col].count()\n","        return 100 if unique_ratio < 0.5 else 0\n","    return 100\n","consistency = {col: check_consistency(col) for col in df.columns}\n","quality_report['Consistency (%)'] = pd.Series(consistency)\n","\n","# 5. Timeliness (% of recent entries in 'date' column if exists)\n","if 'date' in df.columns:\n","    try:\n","        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n","        recent_cutoff = datetime.now() - pd.DateOffset(years=1)\n","        timely_percent = 100 * (df['date'] >= recent_cutoff).sum() / df['date'].notnull().sum()\n","        quality_report['Timeliness (%)'] = pd.Series([round(timely_percent, 2)] * len(df.columns), index=df.columns)\n","    except:\n","        quality_report['Timeliness (%)'] = pd.Series([\"Invalid date format\"] * len(df.columns), index=df.columns)\n","else:\n","    quality_report['Timeliness (%)'] = pd.Series([\"No date column\"] * len(df.columns), index=df.columns)\n","\n","# Combine into a DataFrame\n","dq_report = pd.DataFrame(quality_report)\n","\n","# Display the report\n","print(\"=== Data Quality Report (ISO 8000 Framework) ===\")\n","print(dq_report)\n","\n","# Optional: Save to CSV\n","dq_report.to_csv(\"data_quality_framework_report.csv\")\n","[1:40 pm, 07/05/2025] Kavya Shree: # Ques_1.ipynb â€” Measuring Data Accuracy Using Trusted Source\n","\n","import pandas as pd\n","\n","# Load the datasets\n","company_df = pd.read_csv(\"company_prices.csv\")   # Your company's data\n","trusted_df = pd.read_csv(\"trusted_prices.csv\")   # Trusted reference data\n","\n","# Display basic info (optional)\n","print(\"Company Data Sample:\\n\", company_df.head())\n","print(\"\\nTrusted Data Sample:\\n\", trusted_df.head())\n","\n","# Merge on product_id to align prices\n","merged_df = pd.merge(company_df, trusted_df, on=\"product_id\", suffixes=('_company', '_trusted'))\n","\n","# Create a new column to flag whether prices match\n","merged_df[\"price_match\"] = merged_df[\"price_company\"] == merged_df[\"price_trusted\"]\n","\n","# Accuracy Calculation\n","total_products = len(merged_df)\n","matching_prices = merged_df[\"price_match\"].sum()\n","accuracy_percent = (matching_prices / total_products) * 100\n","\n","# Output results\n","print(f\"\\nTotal Products Compared: {total_products}\")\n","print(f\"Matching Prices: {matching_prices}\")\n","print(f\"Accuracy: {accuracy_percent:.2f}%\")\n","\n","# Show mismatched records (if any)\n","mismatches = merged_df[~merged_df[\"price_match\"]]\n","print(\"\\nMismatched Records:\\n\", mismatches)\n","\n","# Optional: Save results\n","merged_df.to_csv(\"price_accuracy_report.csv\", index=False)\n","mismatches.to_csv(\"price_mismatches.csv\", index=False)"]}]}