{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "# Replace with your actual dataset path if needed\n",
        "df = pd.read_csv(\"your_dataset.csv\")\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nDataset Shape:\")\n",
        "print(df.shape)\n",
        "\n",
        "print(\"\\nFirst 5 Rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "# ------------------------------------------\n",
        "# Step 1: Check for Missing Values\n",
        "# ------------------------------------------\n",
        "print(\"\\nMissing Values:\")\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
        "print(missing_data)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Step 2: Check for Duplicates\n",
        "# ------------------------------------------\n",
        "print(\"\\nDuplicate Rows:\")\n",
        "duplicate_rows = df[df.duplicated()]\n",
        "print(duplicate_rows)\n",
        "\n",
        "print(f\"\\nTotal Duplicates: {duplicate_rows.shape[0]}\")\n",
        "\n",
        "# Optionally remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# ------------------------------------------\n",
        "# Step 3: Check for Data Inconsistencies\n",
        "# (e.g., inconsistent casing, misspellings)\n",
        "# ------------------------------------------\n",
        "print(\"\\nUnique Values in Categorical Columns:\")\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    print(f\"{col} -> {df[col].unique()}\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# Step 4: Check Data Types\n",
        "# ------------------------------------------\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Step 5: Basic Statistical Analysis\n",
        "# ------------------------------------------\n",
        "print(\"\\nMean Values:\")\n",
        "print(df.select_dtypes(include=np.number).mean())\n",
        "\n",
        "print(\"\\nMedian Values:\")\n",
        "print(df.select_dtypes(include=np.number).median())\n",
        "\n",
        "print(\"\\nStandard Deviation:\")\n",
        "print(df.select_dtypes(include=np.number).std())\n",
        "\n",
        "# ------------------------------------------\n",
        "# Step 6: Generate Data Profiling Report\n",
        "# ------------------------------------------\n",
        "# Install the library (uncomment if not already installed)\n",
        "# !pip install ydata-profiling\n",
        "\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(df, title=\"Data Profiling Report\", explorative=True)\n",
        "profile.to_file(\"data_profiling_report.html\")\n",
        "\n",
        "print(\"\\nData profiling report has been generated and saved as 'data_profiling_report.html'.\")"
      ],
      "metadata": {
        "id": "Yzxj5UjITmSb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}