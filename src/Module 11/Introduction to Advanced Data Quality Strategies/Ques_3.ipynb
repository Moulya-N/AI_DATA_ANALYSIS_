{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Step 2: Load your dataset\n",
        "df = pd.read_csv('your_data.csv')  # Replace with your actual data file\n",
        "print(df.head())\n",
        "\n",
        "# Step 3: Explore and clean the data\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Optional: Fill or drop missing values\n",
        "df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Step 4: Feature engineering (e.g., label encoding, removing irrelevant columns)\n",
        "le = LabelEncoder()\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "# Step 5: Define target variable and features\n",
        "X = df.drop('target_column', axis=1)  # Replace with actual target column\n",
        "y = df['target_column']\n",
        "\n",
        "# Step 6: Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 7: Normalize features (if needed)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train machine learning model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 9: Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Step 10: Evaluate the model\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Step 11: Feature importance (optional)\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=importances, y=feature_names)\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AIiD2IgB2O86"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}