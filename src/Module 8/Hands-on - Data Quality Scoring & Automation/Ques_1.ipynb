{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsGwj_WHMVhZ"
      },
      "outputs": [],
      "source": [
        "# Ques_1.ipynb â€“ Understanding and Defining Data Quality Metrics\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the dataset (replace with your dataset path)\n",
        "df = pd.read_csv(\"your_dataset.csv\")  # replace with actual file\n",
        "\n",
        "# Display basic info\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"First 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "# -----------------------------\n",
        "# 1. COMPLETENESS\n",
        "# -----------------------------\n",
        "missing_data = df.isnull().sum()\n",
        "total_cells = df.size\n",
        "missing_cells = missing_data.sum()\n",
        "completeness_score = 1 - (missing_cells / total_cells)\n",
        "print(f\"Completeness Score: {completeness_score:.2f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. UNIQUENESS\n",
        "# -----------------------------\n",
        "duplicate_count = df.duplicated().sum()\n",
        "uniqueness_score = 1 - (duplicate_count / len(df))\n",
        "print(f\"Uniqueness Score: {uniqueness_score:.2f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3. VALIDITY\n",
        "# Example: Check if 'age' column only contains positive integers\n",
        "# -----------------------------\n",
        "if 'age' in df.columns:\n",
        "    valid_age_count = df['age'].apply(lambda x: pd.notnull(x) and x > 0).sum()\n",
        "    validity_score = valid_age_count / df['age'].notnull().sum()\n",
        "else:\n",
        "    validity_score = np.nan\n",
        "    print(\"Column 'age' not found.\")\n",
        "print(f\"Validity Score: {validity_score:.2f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 4. CONSISTENCY\n",
        "# Example: Check if end_date >= start_date\n",
        "# -----------------------------\n",
        "if 'start_date' in df.columns and 'end_date' in df.columns:\n",
        "    df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce')\n",
        "    df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')\n",
        "    consistent_rows = df[df['end_date'] >= df['start_date']].shape[0]\n",
        "    consistency_score = consistent_rows / len(df)\n",
        "else:\n",
        "    consistency_score = np.nan\n",
        "    print(\"Required date columns not found.\")\n",
        "print(f\"Consistency Score: {consistency_score:.2f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. TIMELINESS\n",
        "# Example: Is the latest record within the last 30 days?\n",
        "# -----------------------------\n",
        "if 'date_column' in df.columns:\n",
        "    df['date_column'] = pd.to_datetime(df['date_column'], errors='coerce')\n",
        "    latest_date = df['date_column'].max()\n",
        "    if pd.notnull(latest_date):\n",
        "        days_diff = (datetime.now() - latest_date).days\n",
        "        timeliness_score = 1 if days_diff <= 30 else 0\n",
        "    else:\n",
        "        timeliness_score = np.nan\n",
        "else:\n",
        "    timeliness_score = np.nan\n",
        "    print(\"Column 'date_column' not found.\")\n",
        "print(f\"Timeliness Score: {timeliness_score}\")\n",
        "\n",
        "# -----------------------------\n",
        "# OVERALL DATA QUALITY SCORE (Optional)\n",
        "# -----------------------------\n",
        "# Assign weights based on importance\n",
        "weights = {\n",
        "    'completeness': 0.3,\n",
        "    'uniqueness': 0.2,\n",
        "    'validity': 0.2,\n",
        "    'consistency': 0.2,\n",
        "    'timeliness': 0.1\n",
        "}\n",
        "\n",
        "# Multiply scores by weights and ignore missing metrics (NaNs)\n",
        "metrics = {\n",
        "    'completeness': completeness_score,\n",
        "    'uniqueness': uniqueness_score,\n",
        "    'validity': validity_score,\n",
        "    'consistency': consistency_score,\n",
        "    'timeliness': timeliness_score\n",
        "}\n",
        "\n",
        "weighted_sum = sum(weights[k] * metrics[k] for k in metrics if not np.isnan(metrics[k]))\n",
        "total_weight = sum(weights[k] for k in metrics if not np.isnan(metrics[k]))\n",
        "overall_score = weighted_sum / total_weight if total_weight > 0 else np.nan\n",
        "\n",
        "print(f\"\\nOverall Data Quality Score: {overall_score:.2f}\")"
      ]
    }
  ]
}