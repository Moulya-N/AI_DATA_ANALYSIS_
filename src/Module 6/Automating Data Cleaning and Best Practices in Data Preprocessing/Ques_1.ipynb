{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNj9dOwtDJSl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Separate features by type\n",
        "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create pipelines\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine pipelines\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_pipeline, numeric_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "# Fit and transform the data\n",
        "processed_data = preprocessor.fit_transform(df)"
      ],
      "metadata": {
        "id": "1wfmoTJwDWrx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}